# Toxic-Comment-Classification
Challenge is to build a multi-headed model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate. Data comprises of comments from Wikipedia’s talk page edits.
For more details click the link https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge
